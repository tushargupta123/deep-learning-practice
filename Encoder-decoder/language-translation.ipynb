{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input,Dense,LSTM\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "latent_dim = 256\n",
    "num_samples=10000\n",
    "data_path='fra.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the data\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "with open(data_path,'r',encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "for line in lines[:min(num_samples,len(lines)-1)]:\n",
    "    input_text,target_text,_=line.split('\\t')\n",
    "    target_text= '\\t'+target_text+'\\n'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict(\n",
    "    [(char,i) for i ,char in enumerate(input_characters)]\n",
    ")\n",
    "target_token_index = dict(\n",
    "    [(char,i) for i ,char in enumerate(target_characters)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " '!': 1,\n",
       " '\"': 2,\n",
       " '$': 3,\n",
       " '%': 4,\n",
       " '&': 5,\n",
       " \"'\": 6,\n",
       " ',': 7,\n",
       " '-': 8,\n",
       " '.': 9,\n",
       " '0': 10,\n",
       " '1': 11,\n",
       " '2': 12,\n",
       " '3': 13,\n",
       " '5': 14,\n",
       " '7': 15,\n",
       " '8': 16,\n",
       " '9': 17,\n",
       " ':': 18,\n",
       " '?': 19,\n",
       " 'A': 20,\n",
       " 'B': 21,\n",
       " 'C': 22,\n",
       " 'D': 23,\n",
       " 'E': 24,\n",
       " 'F': 25,\n",
       " 'G': 26,\n",
       " 'H': 27,\n",
       " 'I': 28,\n",
       " 'J': 29,\n",
       " 'K': 30,\n",
       " 'L': 31,\n",
       " 'M': 32,\n",
       " 'N': 33,\n",
       " 'O': 34,\n",
       " 'P': 35,\n",
       " 'Q': 36,\n",
       " 'R': 37,\n",
       " 'S': 38,\n",
       " 'T': 39,\n",
       " 'U': 40,\n",
       " 'V': 41,\n",
       " 'W': 42,\n",
       " 'Y': 43,\n",
       " 'a': 44,\n",
       " 'b': 45,\n",
       " 'c': 46,\n",
       " 'd': 47,\n",
       " 'e': 48,\n",
       " 'f': 49,\n",
       " 'g': 50,\n",
       " 'h': 51,\n",
       " 'i': 52,\n",
       " 'j': 53,\n",
       " 'k': 54,\n",
       " 'l': 55,\n",
       " 'm': 56,\n",
       " 'n': 57,\n",
       " 'o': 58,\n",
       " 'p': 59,\n",
       " 'q': 60,\n",
       " 'r': 61,\n",
       " 's': 62,\n",
       " 't': 63,\n",
       " 'u': 64,\n",
       " 'v': 65,\n",
       " 'w': 66,\n",
       " 'x': 67,\n",
       " 'y': 68,\n",
       " 'z': 69}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_token_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = np.zeros((len(input_texts),max_encoder_seq_length,num_encoder_tokens),dtype='float32')\n",
    "decoder_input_data = np.zeros((len(input_texts),max_decoder_seq_length,num_decoder_tokens),dtype='float32')\n",
    "decoder_target_data = np.zeros((len(input_texts),max_decoder_seq_length,num_decoder_tokens),dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,(input_text,target_text) in enumerate(zip(input_texts,target_texts)):\n",
    "    for t ,char in enumerate(input_text):\n",
    "        encoder_input_data[i,t,input_token_index[char]] = 1.\n",
    "    encoder_input_data[i,t+1:,input_token_index[' ']] = 1.\n",
    "    for t,char in enumerate(target_text):\n",
    "        decoder_input_data[i,t,target_token_index[char]] = 1.\n",
    "        if t>0:\n",
    "            decoder_target_data[i,t-1,target_token_index[char]] = 1.\n",
    "    decoder_input_data[i,t+1:,target_token_index[' ']] = 1.\n",
    "    decoder_target_data[i,t:,target_token_index[' ']] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the input sequence\n",
    "encoder_inputs = Input(shape=(None,num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim,return_state=True)\n",
    "encoder_outputs,state_h,state_c = encoder(encoder_inputs)\n",
    "encoder_states = [state_h,state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the decoder\n",
    "decoder_inputs = Input(shape=(None,num_decoder_tokens))\n",
    "decoder_lstm = LSTM(latent_dim,return_state=True,return_sequences=True)\n",
    "decoder_outputs,_,_ = decoder_lstm(decoder_inputs,initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens,activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "125/125 [==============================] - 21s 152ms/step - loss: 0.0742 - accuracy: 0.7244 - val_loss: 0.0226 - val_accuracy: 0.7049\n",
      "Epoch 2/100\n",
      "125/125 [==============================] - 19s 148ms/step - loss: 0.0193 - accuracy: 0.7373 - val_loss: 0.0190 - val_accuracy: 0.7049\n",
      "Epoch 3/100\n",
      "125/125 [==============================] - 19s 149ms/step - loss: 0.0171 - accuracy: 0.7375 - val_loss: 0.0179 - val_accuracy: 0.7049\n",
      "Epoch 4/100\n",
      "125/125 [==============================] - 20s 157ms/step - loss: 0.0163 - accuracy: 0.7376 - val_loss: 0.0175 - val_accuracy: 0.7049\n",
      "Epoch 5/100\n",
      "125/125 [==============================] - 18s 148ms/step - loss: 0.0158 - accuracy: 0.7368 - val_loss: 0.0172 - val_accuracy: 0.7049\n",
      "Epoch 6/100\n",
      "125/125 [==============================] - 19s 155ms/step - loss: 0.0155 - accuracy: 0.7356 - val_loss: 0.0168 - val_accuracy: 0.6968\n",
      "Epoch 7/100\n",
      "125/125 [==============================] - 18s 148ms/step - loss: 0.0152 - accuracy: 0.7353 - val_loss: 0.0167 - val_accuracy: 0.6995\n",
      "Epoch 8/100\n",
      "125/125 [==============================] - 18s 148ms/step - loss: 0.0149 - accuracy: 0.7386 - val_loss: 0.0163 - val_accuracy: 0.6989\n",
      "Epoch 9/100\n",
      "125/125 [==============================] - 18s 146ms/step - loss: 0.0147 - accuracy: 0.7398 - val_loss: 0.0160 - val_accuracy: 0.7075\n",
      "Epoch 10/100\n",
      "125/125 [==============================] - 19s 148ms/step - loss: 0.0145 - accuracy: 0.7411 - val_loss: 0.0157 - val_accuracy: 0.7035\n",
      "Epoch 11/100\n",
      "125/125 [==============================] - 19s 149ms/step - loss: 0.0143 - accuracy: 0.7428 - val_loss: 0.0159 - val_accuracy: 0.7132\n",
      "Epoch 12/100\n",
      "125/125 [==============================] - 18s 144ms/step - loss: 0.0142 - accuracy: 0.7438 - val_loss: 0.0168 - val_accuracy: 0.7092\n",
      "Epoch 13/100\n",
      "125/125 [==============================] - 19s 149ms/step - loss: 0.0140 - accuracy: 0.7439 - val_loss: 0.0155 - val_accuracy: 0.7132\n",
      "Epoch 14/100\n",
      "125/125 [==============================] - 18s 146ms/step - loss: 0.0139 - accuracy: 0.7430 - val_loss: 0.0152 - val_accuracy: 0.7122\n",
      "Epoch 15/100\n",
      "125/125 [==============================] - 18s 144ms/step - loss: 0.0138 - accuracy: 0.7434 - val_loss: 0.0151 - val_accuracy: 0.7097\n",
      "Epoch 16/100\n",
      "125/125 [==============================] - 18s 140ms/step - loss: 0.0137 - accuracy: 0.7421 - val_loss: 0.0151 - val_accuracy: 0.7153\n",
      "Epoch 17/100\n",
      "125/125 [==============================] - 18s 140ms/step - loss: 0.0136 - accuracy: 0.7425 - val_loss: 0.0149 - val_accuracy: 0.7081\n",
      "Epoch 18/100\n",
      "125/125 [==============================] - 18s 143ms/step - loss: 0.0136 - accuracy: 0.7410 - val_loss: 0.0149 - val_accuracy: 0.7088\n",
      "Epoch 19/100\n",
      "125/125 [==============================] - 17s 140ms/step - loss: 0.0135 - accuracy: 0.7417 - val_loss: 0.0148 - val_accuracy: 0.7106\n",
      "Epoch 20/100\n",
      "125/125 [==============================] - 17s 136ms/step - loss: 0.0134 - accuracy: 0.7414 - val_loss: 0.0148 - val_accuracy: 0.7078\n",
      "Epoch 21/100\n",
      "125/125 [==============================] - 17s 137ms/step - loss: 0.0134 - accuracy: 0.7415 - val_loss: 0.0147 - val_accuracy: 0.7082\n",
      "Epoch 22/100\n",
      "125/125 [==============================] - 17s 138ms/step - loss: 0.0133 - accuracy: 0.7420 - val_loss: 0.0147 - val_accuracy: 0.7052\n",
      "Epoch 23/100\n",
      "125/125 [==============================] - 17s 135ms/step - loss: 0.0133 - accuracy: 0.7416 - val_loss: 0.0146 - val_accuracy: 0.7071\n",
      "Epoch 24/100\n",
      "125/125 [==============================] - 17s 138ms/step - loss: 0.0132 - accuracy: 0.7425 - val_loss: 0.0145 - val_accuracy: 0.7073\n",
      "Epoch 25/100\n",
      "125/125 [==============================] - 17s 138ms/step - loss: 0.0133 - accuracy: 0.7416 - val_loss: 0.0145 - val_accuracy: 0.7139\n",
      "Epoch 26/100\n",
      "125/125 [==============================] - 17s 138ms/step - loss: 0.0133 - accuracy: 0.7415 - val_loss: 0.0145 - val_accuracy: 0.7117\n",
      "Epoch 27/100\n",
      "125/125 [==============================] - 17s 139ms/step - loss: 0.0132 - accuracy: 0.7417 - val_loss: 0.0144 - val_accuracy: 0.7108\n",
      "Epoch 28/100\n",
      "125/125 [==============================] - 17s 139ms/step - loss: 0.0132 - accuracy: 0.7436 - val_loss: 0.0144 - val_accuracy: 0.7127\n",
      "Epoch 29/100\n",
      "125/125 [==============================] - 19s 149ms/step - loss: 0.0130 - accuracy: 0.7466 - val_loss: 0.0144 - val_accuracy: 0.7162\n",
      "Epoch 30/100\n",
      "125/125 [==============================] - 19s 152ms/step - loss: 0.0131 - accuracy: 0.7472 - val_loss: 0.0144 - val_accuracy: 0.7128\n",
      "Epoch 31/100\n",
      "125/125 [==============================] - 19s 150ms/step - loss: 0.0131 - accuracy: 0.7467 - val_loss: 0.0143 - val_accuracy: 0.7162\n",
      "Epoch 32/100\n",
      "125/125 [==============================] - 19s 152ms/step - loss: 0.0129 - accuracy: 0.7471 - val_loss: 0.0143 - val_accuracy: 0.7141\n",
      "Epoch 33/100\n",
      "125/125 [==============================] - 18s 148ms/step - loss: 0.0129 - accuracy: 0.7474 - val_loss: 0.0142 - val_accuracy: 0.7157\n",
      "Epoch 34/100\n",
      "125/125 [==============================] - 18s 148ms/step - loss: 0.0129 - accuracy: 0.7475 - val_loss: 0.0142 - val_accuracy: 0.7152\n",
      "Epoch 35/100\n",
      "125/125 [==============================] - 19s 151ms/step - loss: 0.0130 - accuracy: 0.7483 - val_loss: 0.0142 - val_accuracy: 0.7148\n",
      "Epoch 36/100\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.0128 - accuracy: 0.7488 - val_loss: 0.0141 - val_accuracy: 0.7215\n",
      "Epoch 37/100\n",
      "125/125 [==============================] - 20s 159ms/step - loss: 0.0128 - accuracy: 0.7498 - val_loss: 0.0141 - val_accuracy: 0.7163\n",
      "Epoch 38/100\n",
      "125/125 [==============================] - 17s 138ms/step - loss: 0.0130 - accuracy: 0.7446 - val_loss: 0.0142 - val_accuracy: 0.7180\n",
      "Epoch 39/100\n",
      "125/125 [==============================] - 18s 142ms/step - loss: 0.0130 - accuracy: 0.7446 - val_loss: 0.0143 - val_accuracy: 0.7080\n",
      "Epoch 40/100\n",
      "125/125 [==============================] - 19s 153ms/step - loss: 0.0128 - accuracy: 0.7454 - val_loss: 0.0141 - val_accuracy: 0.7230\n",
      "Epoch 41/100\n",
      "125/125 [==============================] - 19s 155ms/step - loss: 0.0127 - accuracy: 0.7509 - val_loss: 0.0141 - val_accuracy: 0.7229\n",
      "Epoch 42/100\n",
      "125/125 [==============================] - 19s 152ms/step - loss: 0.0130 - accuracy: 0.7503 - val_loss: 0.0141 - val_accuracy: 0.7184\n",
      "Epoch 43/100\n",
      "125/125 [==============================] - 19s 154ms/step - loss: 0.0129 - accuracy: 0.7483 - val_loss: 0.0140 - val_accuracy: 0.7242\n",
      "Epoch 44/100\n",
      "125/125 [==============================] - 21s 165ms/step - loss: 0.0127 - accuracy: 0.7524 - val_loss: 0.0143 - val_accuracy: 0.7131\n",
      "Epoch 45/100\n",
      "125/125 [==============================] - 20s 160ms/step - loss: 0.0128 - accuracy: 0.7525 - val_loss: 0.0140 - val_accuracy: 0.7215\n",
      "Epoch 46/100\n",
      "125/125 [==============================] - 19s 151ms/step - loss: 0.0126 - accuracy: 0.7532 - val_loss: 0.0140 - val_accuracy: 0.7237\n",
      "Epoch 47/100\n",
      "125/125 [==============================] - 20s 158ms/step - loss: 0.0127 - accuracy: 0.7534 - val_loss: 0.0140 - val_accuracy: 0.7204\n",
      "Epoch 48/100\n",
      "125/125 [==============================] - 20s 160ms/step - loss: 0.0126 - accuracy: 0.7550 - val_loss: 0.0139 - val_accuracy: 0.7247\n",
      "Epoch 49/100\n",
      "125/125 [==============================] - 20s 162ms/step - loss: 0.0127 - accuracy: 0.7550 - val_loss: 0.0139 - val_accuracy: 0.7295\n",
      "Epoch 50/100\n",
      "125/125 [==============================] - 20s 157ms/step - loss: 0.0127 - accuracy: 0.7562 - val_loss: 0.0139 - val_accuracy: 0.7291\n",
      "Epoch 51/100\n",
      "125/125 [==============================] - 20s 156ms/step - loss: 0.0126 - accuracy: 0.7569 - val_loss: 0.0138 - val_accuracy: 0.7280\n",
      "Epoch 52/100\n",
      "125/125 [==============================] - 19s 154ms/step - loss: 0.0125 - accuracy: 0.7583 - val_loss: 0.0138 - val_accuracy: 0.7332\n",
      "Epoch 53/100\n",
      "125/125 [==============================] - 20s 157ms/step - loss: 0.0125 - accuracy: 0.7595 - val_loss: 0.0140 - val_accuracy: 0.7270\n",
      "Epoch 54/100\n",
      "125/125 [==============================] - 19s 155ms/step - loss: 0.0125 - accuracy: 0.7594 - val_loss: 0.0139 - val_accuracy: 0.7271\n",
      "Epoch 55/100\n",
      "125/125 [==============================] - 20s 157ms/step - loss: 0.0124 - accuracy: 0.7613 - val_loss: 0.0137 - val_accuracy: 0.7357\n",
      "Epoch 56/100\n",
      "125/125 [==============================] - 20s 157ms/step - loss: 0.0125 - accuracy: 0.7619 - val_loss: 0.0137 - val_accuracy: 0.7328\n",
      "Epoch 57/100\n",
      "125/125 [==============================] - 19s 154ms/step - loss: 0.0124 - accuracy: 0.7625 - val_loss: 0.0137 - val_accuracy: 0.7363\n",
      "Epoch 58/100\n",
      "125/125 [==============================] - 19s 155ms/step - loss: 0.0124 - accuracy: 0.7634 - val_loss: 0.0137 - val_accuracy: 0.7360\n",
      "Epoch 59/100\n",
      "125/125 [==============================] - 19s 156ms/step - loss: 0.0123 - accuracy: 0.7639 - val_loss: 0.0136 - val_accuracy: 0.7372\n",
      "Epoch 60/100\n",
      "125/125 [==============================] - 19s 153ms/step - loss: 0.0124 - accuracy: 0.7641 - val_loss: 0.0136 - val_accuracy: 0.7369\n",
      "Epoch 61/100\n",
      "125/125 [==============================] - 19s 155ms/step - loss: 0.0123 - accuracy: 0.7650 - val_loss: 0.0136 - val_accuracy: 0.7385\n",
      "Epoch 62/100\n",
      "125/125 [==============================] - 19s 151ms/step - loss: 0.0123 - accuracy: 0.7661 - val_loss: 0.0136 - val_accuracy: 0.7382\n",
      "Epoch 63/100\n",
      "125/125 [==============================] - 19s 154ms/step - loss: 0.0122 - accuracy: 0.7670 - val_loss: 0.0135 - val_accuracy: 0.7386\n",
      "Epoch 64/100\n",
      "125/125 [==============================] - 20s 159ms/step - loss: 0.0122 - accuracy: 0.7676 - val_loss: 0.0135 - val_accuracy: 0.7397\n",
      "Epoch 65/100\n",
      "125/125 [==============================] - 19s 155ms/step - loss: 0.0122 - accuracy: 0.7678 - val_loss: 0.0135 - val_accuracy: 0.7406\n",
      "Epoch 66/100\n",
      "125/125 [==============================] - 20s 159ms/step - loss: 0.0122 - accuracy: 0.7689 - val_loss: 0.0135 - val_accuracy: 0.7425\n",
      "Epoch 67/100\n",
      "125/125 [==============================] - 20s 156ms/step - loss: 0.0121 - accuracy: 0.7698 - val_loss: 0.0135 - val_accuracy: 0.7440\n",
      "Epoch 68/100\n",
      "125/125 [==============================] - 19s 153ms/step - loss: 0.0121 - accuracy: 0.7705 - val_loss: 0.0134 - val_accuracy: 0.7448\n",
      "Epoch 69/100\n",
      "125/125 [==============================] - 19s 154ms/step - loss: 0.0121 - accuracy: 0.7712 - val_loss: 0.0134 - val_accuracy: 0.7419\n",
      "Epoch 70/100\n",
      "125/125 [==============================] - 20s 160ms/step - loss: 0.0122 - accuracy: 0.7716 - val_loss: 0.0134 - val_accuracy: 0.7437\n",
      "Epoch 71/100\n",
      "125/125 [==============================] - 19s 155ms/step - loss: 0.0121 - accuracy: 0.7724 - val_loss: 0.0134 - val_accuracy: 0.7473\n",
      "Epoch 72/100\n",
      "125/125 [==============================] - 17s 134ms/step - loss: 0.0120 - accuracy: 0.7732 - val_loss: 0.0133 - val_accuracy: 0.7441\n",
      "Epoch 73/100\n",
      "125/125 [==============================] - 17s 135ms/step - loss: 0.0120 - accuracy: 0.7734 - val_loss: 0.0134 - val_accuracy: 0.7474\n",
      "Epoch 74/100\n",
      "125/125 [==============================] - 17s 137ms/step - loss: 0.0120 - accuracy: 0.7743 - val_loss: 0.0133 - val_accuracy: 0.7484\n",
      "Epoch 75/100\n",
      "125/125 [==============================] - 17s 138ms/step - loss: 0.0120 - accuracy: 0.7751 - val_loss: 0.0133 - val_accuracy: 0.7480\n",
      "Epoch 76/100\n",
      "125/125 [==============================] - 19s 149ms/step - loss: 0.0120 - accuracy: 0.7752 - val_loss: 0.0132 - val_accuracy: 0.7481\n",
      "Epoch 77/100\n",
      "125/125 [==============================] - 20s 159ms/step - loss: 0.0119 - accuracy: 0.7764 - val_loss: 0.0132 - val_accuracy: 0.7499\n",
      "Epoch 78/100\n",
      "125/125 [==============================] - 20s 157ms/step - loss: 0.0119 - accuracy: 0.7764 - val_loss: 0.0132 - val_accuracy: 0.7460\n",
      "Epoch 79/100\n",
      "125/125 [==============================] - 19s 154ms/step - loss: 0.0119 - accuracy: 0.7768 - val_loss: 0.0132 - val_accuracy: 0.7489\n",
      "Epoch 80/100\n",
      "125/125 [==============================] - 19s 154ms/step - loss: 0.0119 - accuracy: 0.7770 - val_loss: 0.0131 - val_accuracy: 0.7483\n",
      "Epoch 81/100\n",
      "125/125 [==============================] - 19s 150ms/step - loss: 0.0119 - accuracy: 0.7772 - val_loss: 0.0131 - val_accuracy: 0.7472\n",
      "Epoch 82/100\n",
      "125/125 [==============================] - 18s 147ms/step - loss: 0.0118 - accuracy: 0.7774 - val_loss: 0.0131 - val_accuracy: 0.7474\n",
      "Epoch 83/100\n",
      "125/125 [==============================] - 17s 139ms/step - loss: 0.0118 - accuracy: 0.7780 - val_loss: 0.0131 - val_accuracy: 0.7488\n",
      "Epoch 84/100\n",
      "125/125 [==============================] - 18s 141ms/step - loss: 0.0118 - accuracy: 0.7782 - val_loss: 0.0131 - val_accuracy: 0.7469\n",
      "Epoch 85/100\n",
      "125/125 [==============================] - 17s 139ms/step - loss: 0.0120 - accuracy: 0.7768 - val_loss: 0.0131 - val_accuracy: 0.7506\n",
      "Epoch 86/100\n",
      "125/125 [==============================] - 17s 138ms/step - loss: 0.0118 - accuracy: 0.7786 - val_loss: 0.0130 - val_accuracy: 0.7472\n",
      "Epoch 87/100\n",
      "125/125 [==============================] - 17s 138ms/step - loss: 0.0117 - accuracy: 0.7784 - val_loss: 0.0130 - val_accuracy: 0.7495\n",
      "Epoch 88/100\n",
      "125/125 [==============================] - 18s 144ms/step - loss: 0.0117 - accuracy: 0.7786 - val_loss: 0.0130 - val_accuracy: 0.7516\n",
      "Epoch 89/100\n",
      "125/125 [==============================] - 18s 146ms/step - loss: 0.0117 - accuracy: 0.7782 - val_loss: 0.0130 - val_accuracy: 0.7499\n",
      "Epoch 90/100\n",
      "125/125 [==============================] - 18s 146ms/step - loss: 0.0116 - accuracy: 0.7787 - val_loss: 0.0130 - val_accuracy: 0.7495\n",
      "Epoch 91/100\n",
      "125/125 [==============================] - 18s 146ms/step - loss: 0.0116 - accuracy: 0.7789 - val_loss: 0.0129 - val_accuracy: 0.7496\n",
      "Epoch 92/100\n",
      "125/125 [==============================] - 18s 147ms/step - loss: 0.0116 - accuracy: 0.7795 - val_loss: 0.0129 - val_accuracy: 0.7476\n",
      "Epoch 93/100\n",
      "125/125 [==============================] - 18s 147ms/step - loss: 0.0116 - accuracy: 0.7795 - val_loss: 0.0129 - val_accuracy: 0.7530\n",
      "Epoch 94/100\n",
      "125/125 [==============================] - 19s 148ms/step - loss: 0.0116 - accuracy: 0.7792 - val_loss: 0.0128 - val_accuracy: 0.7501\n",
      "Epoch 95/100\n",
      "125/125 [==============================] - 19s 149ms/step - loss: 0.0115 - accuracy: 0.7799 - val_loss: 0.0128 - val_accuracy: 0.7503\n",
      "Epoch 96/100\n",
      "125/125 [==============================] - 18s 148ms/step - loss: 0.0115 - accuracy: 0.7795 - val_loss: 0.0128 - val_accuracy: 0.7491\n",
      "Epoch 97/100\n",
      "125/125 [==============================] - 19s 150ms/step - loss: 0.0115 - accuracy: 0.7802 - val_loss: 0.0128 - val_accuracy: 0.7507\n",
      "Epoch 98/100\n",
      "125/125 [==============================] - 18s 147ms/step - loss: 0.0115 - accuracy: 0.7801 - val_loss: 0.0127 - val_accuracy: 0.7510\n",
      "Epoch 99/100\n",
      "125/125 [==============================] - 18s 147ms/step - loss: 0.0115 - accuracy: 0.7803 - val_loss: 0.0127 - val_accuracy: 0.7501\n",
      "Epoch 100/100\n",
      "125/125 [==============================] - 18s 142ms/step - loss: 0.0114 - accuracy: 0.7806 - val_loss: 0.0127 - val_accuracy: 0.7491\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x119fb6d0ad0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the model \n",
    "model = Model([encoder_inputs,decoder_inputs],decoder_outputs)\n",
    "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit([encoder_input_data,decoder_input_data],decoder_target_data,batch_size=batch_size,epochs=epochs,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 351ms/step\n",
      "1/1 [==============================] - 0s 387ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "-\n",
      "input sequence :  Go.\n",
      "decoded sequence :  <function decode_sequence at 0x00000119FFFD7EC0>\n"
     ]
    }
   ],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "reverse_input_char_index = dict((i,char) for char,i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i,char) for char,i in target_token_index.items())\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "for seq_index in range(1):\n",
    "    input_seq = encoder_input_data[seq_index:seq_index+1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('input sequence : ',input_texts[seq_index])\n",
    "    print('decoded sequence : ',decode_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
