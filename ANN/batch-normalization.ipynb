{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense,BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = make_moons(100,noise=0.25,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(2,activation='relu',input_dim=2))\n",
    "model.add(Dense(2,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 71ms/step - loss: 0.6916 - accuracy: 0.5250 - val_loss: 0.6903 - val_accuracy: 0.8000\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6908 - accuracy: 0.6750 - val_loss: 0.6890 - val_accuracy: 0.8000\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6900 - accuracy: 0.6750 - val_loss: 0.6880 - val_accuracy: 0.8000\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6894 - accuracy: 0.6750 - val_loss: 0.6869 - val_accuracy: 0.8000\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6886 - accuracy: 0.6750 - val_loss: 0.6858 - val_accuracy: 0.8000\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6880 - accuracy: 0.6750 - val_loss: 0.6846 - val_accuracy: 0.8000\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6871 - accuracy: 0.6750 - val_loss: 0.6834 - val_accuracy: 0.8000\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6865 - accuracy: 0.6875 - val_loss: 0.6821 - val_accuracy: 0.8000\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6857 - accuracy: 0.6875 - val_loss: 0.6807 - val_accuracy: 0.8000\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6850 - accuracy: 0.6875 - val_loss: 0.6793 - val_accuracy: 0.8000\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6843 - accuracy: 0.6875 - val_loss: 0.6780 - val_accuracy: 0.8000\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6835 - accuracy: 0.6875 - val_loss: 0.6767 - val_accuracy: 0.8000\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6829 - accuracy: 0.6875 - val_loss: 0.6753 - val_accuracy: 0.8000\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6820 - accuracy: 0.6875 - val_loss: 0.6741 - val_accuracy: 0.8000\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6813 - accuracy: 0.6875 - val_loss: 0.6727 - val_accuracy: 0.8000\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6805 - accuracy: 0.6875 - val_loss: 0.6714 - val_accuracy: 0.8000\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6799 - accuracy: 0.6875 - val_loss: 0.6700 - val_accuracy: 0.8000\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6791 - accuracy: 0.6875 - val_loss: 0.6687 - val_accuracy: 0.8000\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6783 - accuracy: 0.6875 - val_loss: 0.6674 - val_accuracy: 0.8000\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6775 - accuracy: 0.6875 - val_loss: 0.6662 - val_accuracy: 0.8000\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6768 - accuracy: 0.6875 - val_loss: 0.6648 - val_accuracy: 0.8000\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6761 - accuracy: 0.6875 - val_loss: 0.6635 - val_accuracy: 0.8000\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6754 - accuracy: 0.6875 - val_loss: 0.6622 - val_accuracy: 0.8000\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6745 - accuracy: 0.6875 - val_loss: 0.6610 - val_accuracy: 0.8000\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6738 - accuracy: 0.7000 - val_loss: 0.6598 - val_accuracy: 0.8000\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6729 - accuracy: 0.7000 - val_loss: 0.6586 - val_accuracy: 0.8000\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6722 - accuracy: 0.7000 - val_loss: 0.6573 - val_accuracy: 0.8000\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6715 - accuracy: 0.7000 - val_loss: 0.6559 - val_accuracy: 0.8000\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6706 - accuracy: 0.7000 - val_loss: 0.6545 - val_accuracy: 0.8000\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6699 - accuracy: 0.7000 - val_loss: 0.6531 - val_accuracy: 0.8000\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6690 - accuracy: 0.7000 - val_loss: 0.6518 - val_accuracy: 0.8000\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6683 - accuracy: 0.7000 - val_loss: 0.6504 - val_accuracy: 0.8000\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6674 - accuracy: 0.7000 - val_loss: 0.6490 - val_accuracy: 0.8000\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6666 - accuracy: 0.7000 - val_loss: 0.6476 - val_accuracy: 0.8000\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6657 - accuracy: 0.7000 - val_loss: 0.6462 - val_accuracy: 0.8000\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6650 - accuracy: 0.7000 - val_loss: 0.6446 - val_accuracy: 0.8000\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6641 - accuracy: 0.7000 - val_loss: 0.6430 - val_accuracy: 0.8000\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6633 - accuracy: 0.7000 - val_loss: 0.6414 - val_accuracy: 0.8000\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6624 - accuracy: 0.6875 - val_loss: 0.6398 - val_accuracy: 0.8000\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6614 - accuracy: 0.6875 - val_loss: 0.6382 - val_accuracy: 0.8000\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6606 - accuracy: 0.6875 - val_loss: 0.6367 - val_accuracy: 0.8000\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6597 - accuracy: 0.6875 - val_loss: 0.6351 - val_accuracy: 0.8000\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6590 - accuracy: 0.6875 - val_loss: 0.6334 - val_accuracy: 0.8000\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6579 - accuracy: 0.6875 - val_loss: 0.6319 - val_accuracy: 0.8000\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6570 - accuracy: 0.6875 - val_loss: 0.6303 - val_accuracy: 0.8000\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6563 - accuracy: 0.6875 - val_loss: 0.6286 - val_accuracy: 0.8000\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6553 - accuracy: 0.7000 - val_loss: 0.6271 - val_accuracy: 0.8000\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6544 - accuracy: 0.7000 - val_loss: 0.6257 - val_accuracy: 0.8000\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6536 - accuracy: 0.7000 - val_loss: 0.6241 - val_accuracy: 0.8000\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6526 - accuracy: 0.7000 - val_loss: 0.6226 - val_accuracy: 0.8000\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6518 - accuracy: 0.7000 - val_loss: 0.6209 - val_accuracy: 0.8000\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6510 - accuracy: 0.7000 - val_loss: 0.6192 - val_accuracy: 0.8000\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6500 - accuracy: 0.7000 - val_loss: 0.6175 - val_accuracy: 0.8000\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6492 - accuracy: 0.7000 - val_loss: 0.6158 - val_accuracy: 0.8000\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6483 - accuracy: 0.7000 - val_loss: 0.6140 - val_accuracy: 0.8000\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6474 - accuracy: 0.7000 - val_loss: 0.6124 - val_accuracy: 0.8000\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6465 - accuracy: 0.7000 - val_loss: 0.6108 - val_accuracy: 0.8000\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6458 - accuracy: 0.7000 - val_loss: 0.6091 - val_accuracy: 0.8000\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6448 - accuracy: 0.7000 - val_loss: 0.6077 - val_accuracy: 0.8000\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6440 - accuracy: 0.7000 - val_loss: 0.6062 - val_accuracy: 0.8000\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6432 - accuracy: 0.7000 - val_loss: 0.6045 - val_accuracy: 0.8000\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6423 - accuracy: 0.7000 - val_loss: 0.6028 - val_accuracy: 0.8000\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6414 - accuracy: 0.7000 - val_loss: 0.6011 - val_accuracy: 0.8000\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6406 - accuracy: 0.7000 - val_loss: 0.5995 - val_accuracy: 0.8000\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6397 - accuracy: 0.7000 - val_loss: 0.5981 - val_accuracy: 0.8000\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6389 - accuracy: 0.7000 - val_loss: 0.5966 - val_accuracy: 0.8000\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6382 - accuracy: 0.7000 - val_loss: 0.5950 - val_accuracy: 0.8000\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6373 - accuracy: 0.7000 - val_loss: 0.5935 - val_accuracy: 0.8000\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6365 - accuracy: 0.7000 - val_loss: 0.5919 - val_accuracy: 0.8000\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6356 - accuracy: 0.7000 - val_loss: 0.5903 - val_accuracy: 0.8000\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6348 - accuracy: 0.7000 - val_loss: 0.5886 - val_accuracy: 0.8000\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6340 - accuracy: 0.7000 - val_loss: 0.5869 - val_accuracy: 0.8000\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6332 - accuracy: 0.7000 - val_loss: 0.5852 - val_accuracy: 0.8000\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6324 - accuracy: 0.7000 - val_loss: 0.5836 - val_accuracy: 0.8000\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6316 - accuracy: 0.7000 - val_loss: 0.5818 - val_accuracy: 0.8000\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6307 - accuracy: 0.7000 - val_loss: 0.5800 - val_accuracy: 0.8000\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6300 - accuracy: 0.7000 - val_loss: 0.5779 - val_accuracy: 0.8000\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6291 - accuracy: 0.7000 - val_loss: 0.5759 - val_accuracy: 0.8000\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6283 - accuracy: 0.7000 - val_loss: 0.5739 - val_accuracy: 0.8000\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6277 - accuracy: 0.7000 - val_loss: 0.5720 - val_accuracy: 0.8000\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6268 - accuracy: 0.7000 - val_loss: 0.5704 - val_accuracy: 0.8000\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6260 - accuracy: 0.7000 - val_loss: 0.5687 - val_accuracy: 0.8000\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6253 - accuracy: 0.7000 - val_loss: 0.5670 - val_accuracy: 0.8000\n",
      "Epoch 84/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6245 - accuracy: 0.7000 - val_loss: 0.5652 - val_accuracy: 0.8000\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6238 - accuracy: 0.7000 - val_loss: 0.5634 - val_accuracy: 0.8000\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6231 - accuracy: 0.7000 - val_loss: 0.5615 - val_accuracy: 0.8000\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6224 - accuracy: 0.7000 - val_loss: 0.5597 - val_accuracy: 0.8000\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6216 - accuracy: 0.7000 - val_loss: 0.5583 - val_accuracy: 0.8000\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6208 - accuracy: 0.7000 - val_loss: 0.5569 - val_accuracy: 0.8000\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6202 - accuracy: 0.7000 - val_loss: 0.5552 - val_accuracy: 0.8000\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6194 - accuracy: 0.7000 - val_loss: 0.5538 - val_accuracy: 0.8000\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6188 - accuracy: 0.7000 - val_loss: 0.5523 - val_accuracy: 0.8000\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6181 - accuracy: 0.7000 - val_loss: 0.5507 - val_accuracy: 0.8000\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6174 - accuracy: 0.7000 - val_loss: 0.5492 - val_accuracy: 0.8000\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6167 - accuracy: 0.7000 - val_loss: 0.5477 - val_accuracy: 0.8000\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6161 - accuracy: 0.7000 - val_loss: 0.5463 - val_accuracy: 0.8000\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6154 - accuracy: 0.7000 - val_loss: 0.5451 - val_accuracy: 0.8000\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6148 - accuracy: 0.7000 - val_loss: 0.5437 - val_accuracy: 0.8000\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6143 - accuracy: 0.7000 - val_loss: 0.5421 - val_accuracy: 0.8000\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6136 - accuracy: 0.7000 - val_loss: 0.5407 - val_accuracy: 0.8000\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6130 - accuracy: 0.7000 - val_loss: 0.5392 - val_accuracy: 0.8000\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6125 - accuracy: 0.7000 - val_loss: 0.5376 - val_accuracy: 0.8000\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6119 - accuracy: 0.7000 - val_loss: 0.5362 - val_accuracy: 0.8000\n",
      "Epoch 104/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6113 - accuracy: 0.7000 - val_loss: 0.5349 - val_accuracy: 0.8000\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6106 - accuracy: 0.7000 - val_loss: 0.5334 - val_accuracy: 0.8000\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6101 - accuracy: 0.7000 - val_loss: 0.5316 - val_accuracy: 0.8500\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6095 - accuracy: 0.7000 - val_loss: 0.5297 - val_accuracy: 0.8500\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6088 - accuracy: 0.7000 - val_loss: 0.5276 - val_accuracy: 0.8500\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6081 - accuracy: 0.7000 - val_loss: 0.5258 - val_accuracy: 0.8500\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6075 - accuracy: 0.7000 - val_loss: 0.5239 - val_accuracy: 0.8500\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6068 - accuracy: 0.7000 - val_loss: 0.5223 - val_accuracy: 0.8500\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6063 - accuracy: 0.7000 - val_loss: 0.5206 - val_accuracy: 0.8500\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6055 - accuracy: 0.7000 - val_loss: 0.5192 - val_accuracy: 0.8500\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6049 - accuracy: 0.7000 - val_loss: 0.5177 - val_accuracy: 0.8500\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6042 - accuracy: 0.7000 - val_loss: 0.5164 - val_accuracy: 0.8500\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6034 - accuracy: 0.7000 - val_loss: 0.5155 - val_accuracy: 0.8500\n",
      "Epoch 117/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6028 - accuracy: 0.7000 - val_loss: 0.5141 - val_accuracy: 0.8500\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6021 - accuracy: 0.7000 - val_loss: 0.5129 - val_accuracy: 0.8500\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6014 - accuracy: 0.7000 - val_loss: 0.5115 - val_accuracy: 0.8500\n",
      "Epoch 120/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6008 - accuracy: 0.7000 - val_loss: 0.5100 - val_accuracy: 0.8500\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6000 - accuracy: 0.7000 - val_loss: 0.5082 - val_accuracy: 0.8500\n",
      "Epoch 122/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5993 - accuracy: 0.7000 - val_loss: 0.5062 - val_accuracy: 0.8500\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5985 - accuracy: 0.7000 - val_loss: 0.5043 - val_accuracy: 0.8500\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5979 - accuracy: 0.7125 - val_loss: 0.5024 - val_accuracy: 0.8500\n",
      "Epoch 125/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5971 - accuracy: 0.7125 - val_loss: 0.5007 - val_accuracy: 0.8500\n",
      "Epoch 126/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5964 - accuracy: 0.7125 - val_loss: 0.4992 - val_accuracy: 0.8500\n",
      "Epoch 127/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5958 - accuracy: 0.7125 - val_loss: 0.4977 - val_accuracy: 0.8500\n",
      "Epoch 128/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5950 - accuracy: 0.7125 - val_loss: 0.4966 - val_accuracy: 0.8500\n",
      "Epoch 129/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5944 - accuracy: 0.7125 - val_loss: 0.4954 - val_accuracy: 0.8500\n",
      "Epoch 130/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5939 - accuracy: 0.7125 - val_loss: 0.4939 - val_accuracy: 0.8500\n",
      "Epoch 131/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5932 - accuracy: 0.7125 - val_loss: 0.4925 - val_accuracy: 0.8500\n",
      "Epoch 132/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5925 - accuracy: 0.7125 - val_loss: 0.4912 - val_accuracy: 0.8500\n",
      "Epoch 133/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5919 - accuracy: 0.7125 - val_loss: 0.4900 - val_accuracy: 0.8500\n",
      "Epoch 134/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5913 - accuracy: 0.7125 - val_loss: 0.4887 - val_accuracy: 0.8500\n",
      "Epoch 135/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5907 - accuracy: 0.7125 - val_loss: 0.4876 - val_accuracy: 0.8500\n",
      "Epoch 136/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5900 - accuracy: 0.7125 - val_loss: 0.4862 - val_accuracy: 0.8500\n",
      "Epoch 137/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5894 - accuracy: 0.7125 - val_loss: 0.4850 - val_accuracy: 0.8500\n",
      "Epoch 138/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5888 - accuracy: 0.7125 - val_loss: 0.4836 - val_accuracy: 0.8500\n",
      "Epoch 139/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5880 - accuracy: 0.7125 - val_loss: 0.4819 - val_accuracy: 0.8500\n",
      "Epoch 140/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5872 - accuracy: 0.7250 - val_loss: 0.4801 - val_accuracy: 0.8500\n",
      "Epoch 141/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5863 - accuracy: 0.7250 - val_loss: 0.4780 - val_accuracy: 0.8500\n",
      "Epoch 142/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5853 - accuracy: 0.7250 - val_loss: 0.4758 - val_accuracy: 0.8500\n",
      "Epoch 143/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5844 - accuracy: 0.7250 - val_loss: 0.4736 - val_accuracy: 0.8500\n",
      "Epoch 144/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5835 - accuracy: 0.7250 - val_loss: 0.4714 - val_accuracy: 0.8500\n",
      "Epoch 145/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5823 - accuracy: 0.7250 - val_loss: 0.4696 - val_accuracy: 0.8500\n",
      "Epoch 146/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5816 - accuracy: 0.7250 - val_loss: 0.4676 - val_accuracy: 0.8500\n",
      "Epoch 147/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5808 - accuracy: 0.7250 - val_loss: 0.4658 - val_accuracy: 0.8500\n",
      "Epoch 148/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5797 - accuracy: 0.7375 - val_loss: 0.4642 - val_accuracy: 0.8500\n",
      "Epoch 149/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5788 - accuracy: 0.7375 - val_loss: 0.4624 - val_accuracy: 0.8500\n",
      "Epoch 150/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5774 - accuracy: 0.7375 - val_loss: 0.4601 - val_accuracy: 0.8500\n",
      "Epoch 151/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5761 - accuracy: 0.7375 - val_loss: 0.4579 - val_accuracy: 0.8500\n",
      "Epoch 152/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5746 - accuracy: 0.7500 - val_loss: 0.4557 - val_accuracy: 0.8500\n",
      "Epoch 153/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5731 - accuracy: 0.7500 - val_loss: 0.4538 - val_accuracy: 0.8500\n",
      "Epoch 154/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5719 - accuracy: 0.7500 - val_loss: 0.4510 - val_accuracy: 0.8500\n",
      "Epoch 155/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5699 - accuracy: 0.7625 - val_loss: 0.4484 - val_accuracy: 0.8500\n",
      "Epoch 156/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5682 - accuracy: 0.7625 - val_loss: 0.4454 - val_accuracy: 0.8500\n",
      "Epoch 157/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5659 - accuracy: 0.7875 - val_loss: 0.4427 - val_accuracy: 0.9000\n",
      "Epoch 158/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5638 - accuracy: 0.7875 - val_loss: 0.4401 - val_accuracy: 0.9000\n",
      "Epoch 159/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5621 - accuracy: 0.7875 - val_loss: 0.4372 - val_accuracy: 0.9000\n",
      "Epoch 160/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5603 - accuracy: 0.8125 - val_loss: 0.4344 - val_accuracy: 0.9000\n",
      "Epoch 161/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5581 - accuracy: 0.8125 - val_loss: 0.4320 - val_accuracy: 0.9000\n",
      "Epoch 162/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5561 - accuracy: 0.8125 - val_loss: 0.4295 - val_accuracy: 0.9000\n",
      "Epoch 163/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5542 - accuracy: 0.8125 - val_loss: 0.4268 - val_accuracy: 0.9000\n",
      "Epoch 164/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5522 - accuracy: 0.8125 - val_loss: 0.4241 - val_accuracy: 0.9000\n",
      "Epoch 165/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5500 - accuracy: 0.8125 - val_loss: 0.4218 - val_accuracy: 0.9000\n",
      "Epoch 166/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5479 - accuracy: 0.8125 - val_loss: 0.4197 - val_accuracy: 0.9000\n",
      "Epoch 167/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5458 - accuracy: 0.8125 - val_loss: 0.4176 - val_accuracy: 0.9000\n",
      "Epoch 168/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5439 - accuracy: 0.8125 - val_loss: 0.4156 - val_accuracy: 0.9000\n",
      "Epoch 169/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5424 - accuracy: 0.8125 - val_loss: 0.4132 - val_accuracy: 0.9000\n",
      "Epoch 170/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5405 - accuracy: 0.8125 - val_loss: 0.4111 - val_accuracy: 0.9000\n",
      "Epoch 171/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5389 - accuracy: 0.8250 - val_loss: 0.4090 - val_accuracy: 0.9000\n",
      "Epoch 172/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5372 - accuracy: 0.8500 - val_loss: 0.4070 - val_accuracy: 0.9000\n",
      "Epoch 173/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5357 - accuracy: 0.8500 - val_loss: 0.4053 - val_accuracy: 0.9000\n",
      "Epoch 174/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5341 - accuracy: 0.8500 - val_loss: 0.4038 - val_accuracy: 0.9000\n",
      "Epoch 175/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5328 - accuracy: 0.8500 - val_loss: 0.4022 - val_accuracy: 0.9000\n",
      "Epoch 176/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5315 - accuracy: 0.8500 - val_loss: 0.4007 - val_accuracy: 0.9000\n",
      "Epoch 177/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5303 - accuracy: 0.8500 - val_loss: 0.3994 - val_accuracy: 0.9000\n",
      "Epoch 178/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5292 - accuracy: 0.8500 - val_loss: 0.3981 - val_accuracy: 0.9000\n",
      "Epoch 179/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5279 - accuracy: 0.8500 - val_loss: 0.3972 - val_accuracy: 0.9000\n",
      "Epoch 180/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5267 - accuracy: 0.8500 - val_loss: 0.3968 - val_accuracy: 0.9000\n",
      "Epoch 181/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5256 - accuracy: 0.8500 - val_loss: 0.3964 - val_accuracy: 0.9000\n",
      "Epoch 182/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5246 - accuracy: 0.8500 - val_loss: 0.3959 - val_accuracy: 0.9000\n",
      "Epoch 183/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5235 - accuracy: 0.8500 - val_loss: 0.3951 - val_accuracy: 0.9000\n",
      "Epoch 184/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5224 - accuracy: 0.8500 - val_loss: 0.3941 - val_accuracy: 0.9000\n",
      "Epoch 185/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5214 - accuracy: 0.8500 - val_loss: 0.3929 - val_accuracy: 0.9000\n",
      "Epoch 186/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5203 - accuracy: 0.8500 - val_loss: 0.3922 - val_accuracy: 0.9000\n",
      "Epoch 187/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5195 - accuracy: 0.8500 - val_loss: 0.3912 - val_accuracy: 0.9000\n",
      "Epoch 188/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5183 - accuracy: 0.8500 - val_loss: 0.3905 - val_accuracy: 0.9000\n",
      "Epoch 189/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5175 - accuracy: 0.8500 - val_loss: 0.3897 - val_accuracy: 0.9000\n",
      "Epoch 190/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5166 - accuracy: 0.8500 - val_loss: 0.3892 - val_accuracy: 0.9000\n",
      "Epoch 191/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5157 - accuracy: 0.8500 - val_loss: 0.3885 - val_accuracy: 0.9000\n",
      "Epoch 192/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5148 - accuracy: 0.8500 - val_loss: 0.3878 - val_accuracy: 0.9000\n",
      "Epoch 193/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5140 - accuracy: 0.8500 - val_loss: 0.3871 - val_accuracy: 0.9000\n",
      "Epoch 194/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5132 - accuracy: 0.8500 - val_loss: 0.3866 - val_accuracy: 0.9000\n",
      "Epoch 195/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5123 - accuracy: 0.8500 - val_loss: 0.3863 - val_accuracy: 0.9000\n",
      "Epoch 196/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5116 - accuracy: 0.8500 - val_loss: 0.3859 - val_accuracy: 0.9000\n",
      "Epoch 197/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5107 - accuracy: 0.8375 - val_loss: 0.3853 - val_accuracy: 0.9000\n",
      "Epoch 198/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5100 - accuracy: 0.8375 - val_loss: 0.3846 - val_accuracy: 0.9000\n",
      "Epoch 199/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5092 - accuracy: 0.8375 - val_loss: 0.3841 - val_accuracy: 0.9000\n",
      "Epoch 200/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5085 - accuracy: 0.8375 - val_loss: 0.3837 - val_accuracy: 0.9000\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "history1 = model.fit(X,y,epochs=200,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 3)                 9         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 3)                 12        \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 8         \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 2)                 8         \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40 (160.00 Byte)\n",
      "Trainable params: 30 (120.00 Byte)\n",
      "Non-trainable params: 10 (40.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(3,activation='relu',input_dim=2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(2,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 66ms/step - loss: 1.0748 - accuracy: 0.2125 - val_loss: 0.7391 - val_accuracy: 0.2000\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.0796 - accuracy: 0.2250 - val_loss: 0.7392 - val_accuracy: 0.2000\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.0654 - accuracy: 0.2125 - val_loss: 0.7396 - val_accuracy: 0.2000\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.0635 - accuracy: 0.2375 - val_loss: 0.7393 - val_accuracy: 0.2000\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.0710 - accuracy: 0.2250 - val_loss: 0.7393 - val_accuracy: 0.2000\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.0629 - accuracy: 0.2250 - val_loss: 0.7394 - val_accuracy: 0.2000\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.0475 - accuracy: 0.2375 - val_loss: 0.7399 - val_accuracy: 0.2500\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.0428 - accuracy: 0.2250 - val_loss: 0.7406 - val_accuracy: 0.2500\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.0480 - accuracy: 0.2375 - val_loss: 0.7409 - val_accuracy: 0.2500\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.0185 - accuracy: 0.2625 - val_loss: 0.7409 - val_accuracy: 0.2500\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.0317 - accuracy: 0.2375 - val_loss: 0.7410 - val_accuracy: 0.2500\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.0360 - accuracy: 0.2250 - val_loss: 0.7412 - val_accuracy: 0.2500\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.0028 - accuracy: 0.2250 - val_loss: 0.7419 - val_accuracy: 0.2500\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.0136 - accuracy: 0.2250 - val_loss: 0.7424 - val_accuracy: 0.2500\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.0079 - accuracy: 0.2500 - val_loss: 0.7428 - val_accuracy: 0.2500\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.9966 - accuracy: 0.2500 - val_loss: 0.7431 - val_accuracy: 0.2500\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.9676 - accuracy: 0.2375 - val_loss: 0.7428 - val_accuracy: 0.2500\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.9909 - accuracy: 0.2375 - val_loss: 0.7427 - val_accuracy: 0.2500\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.9838 - accuracy: 0.2375 - val_loss: 0.7428 - val_accuracy: 0.2500\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.9650 - accuracy: 0.2500 - val_loss: 0.7428 - val_accuracy: 0.2500\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.9814 - accuracy: 0.2250 - val_loss: 0.7428 - val_accuracy: 0.2500\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.9675 - accuracy: 0.2375 - val_loss: 0.7426 - val_accuracy: 0.3000\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.9592 - accuracy: 0.2375 - val_loss: 0.7424 - val_accuracy: 0.3000\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.9390 - accuracy: 0.2250 - val_loss: 0.7423 - val_accuracy: 0.3000\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.9444 - accuracy: 0.2500 - val_loss: 0.7419 - val_accuracy: 0.3000\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.9496 - accuracy: 0.2250 - val_loss: 0.7416 - val_accuracy: 0.3000\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.9301 - accuracy: 0.2500 - val_loss: 0.7413 - val_accuracy: 0.3000\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.9303 - accuracy: 0.2250 - val_loss: 0.7411 - val_accuracy: 0.3000\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.9239 - accuracy: 0.2375 - val_loss: 0.7411 - val_accuracy: 0.3000\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.9274 - accuracy: 0.2625 - val_loss: 0.7413 - val_accuracy: 0.3000\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9104 - accuracy: 0.2375 - val_loss: 0.7413 - val_accuracy: 0.3000\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.9087 - accuracy: 0.2375 - val_loss: 0.7411 - val_accuracy: 0.3000\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.9010 - accuracy: 0.2375 - val_loss: 0.7406 - val_accuracy: 0.3000\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.8880 - accuracy: 0.2375 - val_loss: 0.7405 - val_accuracy: 0.3000\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.8918 - accuracy: 0.2375 - val_loss: 0.7402 - val_accuracy: 0.3000\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.8861 - accuracy: 0.2375 - val_loss: 0.7396 - val_accuracy: 0.2500\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8701 - accuracy: 0.2500 - val_loss: 0.7389 - val_accuracy: 0.2500\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.8778 - accuracy: 0.2375 - val_loss: 0.7382 - val_accuracy: 0.2500\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.8415 - accuracy: 0.2750 - val_loss: 0.7377 - val_accuracy: 0.2500\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8691 - accuracy: 0.2375 - val_loss: 0.7372 - val_accuracy: 0.2500\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.8536 - accuracy: 0.3000 - val_loss: 0.7367 - val_accuracy: 0.2500\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.8539 - accuracy: 0.2500 - val_loss: 0.7363 - val_accuracy: 0.2500\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8447 - accuracy: 0.2750 - val_loss: 0.7361 - val_accuracy: 0.2500\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.8296 - accuracy: 0.2750 - val_loss: 0.7355 - val_accuracy: 0.2500\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.8420 - accuracy: 0.2500 - val_loss: 0.7348 - val_accuracy: 0.2500\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8307 - accuracy: 0.2875 - val_loss: 0.7342 - val_accuracy: 0.2500\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8182 - accuracy: 0.2875 - val_loss: 0.7335 - val_accuracy: 0.2500\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8223 - accuracy: 0.2625 - val_loss: 0.7325 - val_accuracy: 0.2500\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.8140 - accuracy: 0.3000 - val_loss: 0.7320 - val_accuracy: 0.2500\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8140 - accuracy: 0.3000 - val_loss: 0.7316 - val_accuracy: 0.2500\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8088 - accuracy: 0.3000 - val_loss: 0.7310 - val_accuracy: 0.2500\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8083 - accuracy: 0.2500 - val_loss: 0.7305 - val_accuracy: 0.2000\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.7979 - accuracy: 0.2625 - val_loss: 0.7298 - val_accuracy: 0.2500\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7927 - accuracy: 0.2625 - val_loss: 0.7293 - val_accuracy: 0.3000\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.7868 - accuracy: 0.2750 - val_loss: 0.7283 - val_accuracy: 0.3000\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.7833 - accuracy: 0.2625 - val_loss: 0.7272 - val_accuracy: 0.3000\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.7752 - accuracy: 0.2750 - val_loss: 0.7261 - val_accuracy: 0.3000\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.7695 - accuracy: 0.3125 - val_loss: 0.7247 - val_accuracy: 0.3000\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7731 - accuracy: 0.2875 - val_loss: 0.7234 - val_accuracy: 0.3000\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.7609 - accuracy: 0.3250 - val_loss: 0.7222 - val_accuracy: 0.3000\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.7692 - accuracy: 0.3000 - val_loss: 0.7211 - val_accuracy: 0.3000\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.7555 - accuracy: 0.2875 - val_loss: 0.7197 - val_accuracy: 0.3500\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.7505 - accuracy: 0.3125 - val_loss: 0.7185 - val_accuracy: 0.3500\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.7491 - accuracy: 0.3375 - val_loss: 0.7170 - val_accuracy: 0.3500\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.7491 - accuracy: 0.3000 - val_loss: 0.7156 - val_accuracy: 0.3500\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7411 - accuracy: 0.2625 - val_loss: 0.7141 - val_accuracy: 0.3500\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7370 - accuracy: 0.3875 - val_loss: 0.7129 - val_accuracy: 0.4000\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.7396 - accuracy: 0.3875 - val_loss: 0.7116 - val_accuracy: 0.4000\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7308 - accuracy: 0.4625 - val_loss: 0.7105 - val_accuracy: 0.4000\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.7308 - accuracy: 0.4625 - val_loss: 0.7097 - val_accuracy: 0.4000\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.7246 - accuracy: 0.4750 - val_loss: 0.7088 - val_accuracy: 0.4000\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.7201 - accuracy: 0.4750 - val_loss: 0.7079 - val_accuracy: 0.4000\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.7229 - accuracy: 0.4375 - val_loss: 0.7073 - val_accuracy: 0.4500\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.7089 - accuracy: 0.5500 - val_loss: 0.7064 - val_accuracy: 0.4500\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.7118 - accuracy: 0.4875 - val_loss: 0.7057 - val_accuracy: 0.4500\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7134 - accuracy: 0.4625 - val_loss: 0.7049 - val_accuracy: 0.4000\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7078 - accuracy: 0.5000 - val_loss: 0.7043 - val_accuracy: 0.4500\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.7042 - accuracy: 0.4875 - val_loss: 0.7039 - val_accuracy: 0.4500\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.7015 - accuracy: 0.4875 - val_loss: 0.7033 - val_accuracy: 0.4000\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6972 - accuracy: 0.5000 - val_loss: 0.7026 - val_accuracy: 0.4500\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6967 - accuracy: 0.5125 - val_loss: 0.7021 - val_accuracy: 0.4500\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6906 - accuracy: 0.5375 - val_loss: 0.7015 - val_accuracy: 0.4500\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6933 - accuracy: 0.4875 - val_loss: 0.7011 - val_accuracy: 0.4500\n",
      "Epoch 84/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6807 - accuracy: 0.5250 - val_loss: 0.7005 - val_accuracy: 0.4500\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6868 - accuracy: 0.4875 - val_loss: 0.6998 - val_accuracy: 0.5000\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6809 - accuracy: 0.5000 - val_loss: 0.6994 - val_accuracy: 0.4500\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6794 - accuracy: 0.5125 - val_loss: 0.6990 - val_accuracy: 0.4500\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6731 - accuracy: 0.5625 - val_loss: 0.6985 - val_accuracy: 0.4500\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6806 - accuracy: 0.5375 - val_loss: 0.6980 - val_accuracy: 0.4500\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6711 - accuracy: 0.6000 - val_loss: 0.6981 - val_accuracy: 0.4500\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6667 - accuracy: 0.5500 - val_loss: 0.6973 - val_accuracy: 0.4500\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6633 - accuracy: 0.6000 - val_loss: 0.6969 - val_accuracy: 0.4500\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6630 - accuracy: 0.5875 - val_loss: 0.6963 - val_accuracy: 0.4500\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6586 - accuracy: 0.6000 - val_loss: 0.6960 - val_accuracy: 0.4500\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6555 - accuracy: 0.6250 - val_loss: 0.6957 - val_accuracy: 0.4500\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6567 - accuracy: 0.6250 - val_loss: 0.6956 - val_accuracy: 0.4500\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6391 - accuracy: 0.6625 - val_loss: 0.6952 - val_accuracy: 0.4500\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6497 - accuracy: 0.6750 - val_loss: 0.6939 - val_accuracy: 0.4000\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6443 - accuracy: 0.6375 - val_loss: 0.6931 - val_accuracy: 0.4000\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6371 - accuracy: 0.7000 - val_loss: 0.6919 - val_accuracy: 0.4000\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6391 - accuracy: 0.6875 - val_loss: 0.6911 - val_accuracy: 0.4000\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6393 - accuracy: 0.6625 - val_loss: 0.6904 - val_accuracy: 0.4500\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6332 - accuracy: 0.6750 - val_loss: 0.6901 - val_accuracy: 0.4500\n",
      "Epoch 104/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6320 - accuracy: 0.6750 - val_loss: 0.6898 - val_accuracy: 0.4500\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6261 - accuracy: 0.6875 - val_loss: 0.6889 - val_accuracy: 0.4500\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6218 - accuracy: 0.6875 - val_loss: 0.6885 - val_accuracy: 0.4500\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6275 - accuracy: 0.7000 - val_loss: 0.6885 - val_accuracy: 0.4500\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6156 - accuracy: 0.7000 - val_loss: 0.6886 - val_accuracy: 0.4500\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6149 - accuracy: 0.7000 - val_loss: 0.6891 - val_accuracy: 0.4500\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6025 - accuracy: 0.7625 - val_loss: 0.6894 - val_accuracy: 0.4500\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6040 - accuracy: 0.7625 - val_loss: 0.6893 - val_accuracy: 0.4500\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6039 - accuracy: 0.7500 - val_loss: 0.6887 - val_accuracy: 0.4500\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5933 - accuracy: 0.7750 - val_loss: 0.6881 - val_accuracy: 0.4500\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5980 - accuracy: 0.7250 - val_loss: 0.6873 - val_accuracy: 0.5000\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6048 - accuracy: 0.7125 - val_loss: 0.6866 - val_accuracy: 0.5000\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5872 - accuracy: 0.7375 - val_loss: 0.6858 - val_accuracy: 0.5000\n",
      "Epoch 117/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5888 - accuracy: 0.7875 - val_loss: 0.6852 - val_accuracy: 0.5000\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5754 - accuracy: 0.7750 - val_loss: 0.6846 - val_accuracy: 0.5000\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5755 - accuracy: 0.7750 - val_loss: 0.6838 - val_accuracy: 0.5000\n",
      "Epoch 120/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5723 - accuracy: 0.7500 - val_loss: 0.6829 - val_accuracy: 0.5000\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5587 - accuracy: 0.7500 - val_loss: 0.6817 - val_accuracy: 0.5000\n",
      "Epoch 122/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5600 - accuracy: 0.8000 - val_loss: 0.6805 - val_accuracy: 0.5500\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5668 - accuracy: 0.8000 - val_loss: 0.6794 - val_accuracy: 0.5500\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5721 - accuracy: 0.7250 - val_loss: 0.6781 - val_accuracy: 0.5500\n",
      "Epoch 125/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5549 - accuracy: 0.8250 - val_loss: 0.6776 - val_accuracy: 0.5500\n",
      "Epoch 126/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5446 - accuracy: 0.7750 - val_loss: 0.6772 - val_accuracy: 0.5500\n",
      "Epoch 127/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5458 - accuracy: 0.8125 - val_loss: 0.6760 - val_accuracy: 0.6000\n",
      "Epoch 128/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5369 - accuracy: 0.7875 - val_loss: 0.6743 - val_accuracy: 0.6000\n",
      "Epoch 129/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5542 - accuracy: 0.7875 - val_loss: 0.6725 - val_accuracy: 0.6000\n",
      "Epoch 130/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5377 - accuracy: 0.8125 - val_loss: 0.6699 - val_accuracy: 0.6500\n",
      "Epoch 131/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5281 - accuracy: 0.8000 - val_loss: 0.6681 - val_accuracy: 0.6500\n",
      "Epoch 132/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5273 - accuracy: 0.8000 - val_loss: 0.6656 - val_accuracy: 0.6500\n",
      "Epoch 133/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5439 - accuracy: 0.8000 - val_loss: 0.6637 - val_accuracy: 0.6500\n",
      "Epoch 134/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5232 - accuracy: 0.8250 - val_loss: 0.6617 - val_accuracy: 0.6500\n",
      "Epoch 135/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5185 - accuracy: 0.8000 - val_loss: 0.6596 - val_accuracy: 0.6500\n",
      "Epoch 136/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5178 - accuracy: 0.8250 - val_loss: 0.6574 - val_accuracy: 0.6500\n",
      "Epoch 137/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5172 - accuracy: 0.8250 - val_loss: 0.6556 - val_accuracy: 0.6500\n",
      "Epoch 138/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5211 - accuracy: 0.8250 - val_loss: 0.6537 - val_accuracy: 0.6500\n",
      "Epoch 139/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5075 - accuracy: 0.8125 - val_loss: 0.6516 - val_accuracy: 0.6500\n",
      "Epoch 140/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5132 - accuracy: 0.8000 - val_loss: 0.6499 - val_accuracy: 0.6500\n",
      "Epoch 141/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5191 - accuracy: 0.7875 - val_loss: 0.6475 - val_accuracy: 0.6500\n",
      "Epoch 142/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4877 - accuracy: 0.8250 - val_loss: 0.6469 - val_accuracy: 0.6500\n",
      "Epoch 143/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4970 - accuracy: 0.7875 - val_loss: 0.6468 - val_accuracy: 0.6500\n",
      "Epoch 144/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5079 - accuracy: 0.8000 - val_loss: 0.6462 - val_accuracy: 0.6500\n",
      "Epoch 145/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5150 - accuracy: 0.7875 - val_loss: 0.6450 - val_accuracy: 0.6500\n",
      "Epoch 146/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4884 - accuracy: 0.8250 - val_loss: 0.6424 - val_accuracy: 0.6500\n",
      "Epoch 147/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4965 - accuracy: 0.8250 - val_loss: 0.6387 - val_accuracy: 0.6500\n",
      "Epoch 148/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4842 - accuracy: 0.8250 - val_loss: 0.6351 - val_accuracy: 0.6500\n",
      "Epoch 149/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4846 - accuracy: 0.8000 - val_loss: 0.6308 - val_accuracy: 0.6500\n",
      "Epoch 150/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4836 - accuracy: 0.8125 - val_loss: 0.6267 - val_accuracy: 0.6500\n",
      "Epoch 151/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4791 - accuracy: 0.8250 - val_loss: 0.6234 - val_accuracy: 0.6500\n",
      "Epoch 152/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4859 - accuracy: 0.8000 - val_loss: 0.6207 - val_accuracy: 0.6500\n",
      "Epoch 153/200\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.5090 - accuracy: 0.7500 - val_loss: 0.6163 - val_accuracy: 0.6500\n",
      "Epoch 154/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4876 - accuracy: 0.8125 - val_loss: 0.6101 - val_accuracy: 0.7000\n",
      "Epoch 155/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4737 - accuracy: 0.8125 - val_loss: 0.6053 - val_accuracy: 0.7000\n",
      "Epoch 156/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4728 - accuracy: 0.8125 - val_loss: 0.6007 - val_accuracy: 0.7000\n",
      "Epoch 157/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4796 - accuracy: 0.8000 - val_loss: 0.5983 - val_accuracy: 0.7000\n",
      "Epoch 158/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4816 - accuracy: 0.7875 - val_loss: 0.5947 - val_accuracy: 0.7000\n",
      "Epoch 159/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4734 - accuracy: 0.8125 - val_loss: 0.5909 - val_accuracy: 0.7000\n",
      "Epoch 160/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4925 - accuracy: 0.7875 - val_loss: 0.5871 - val_accuracy: 0.7000\n",
      "Epoch 161/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4764 - accuracy: 0.8125 - val_loss: 0.5832 - val_accuracy: 0.7500\n",
      "Epoch 162/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4708 - accuracy: 0.8000 - val_loss: 0.5778 - val_accuracy: 0.7500\n",
      "Epoch 163/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4628 - accuracy: 0.8125 - val_loss: 0.5722 - val_accuracy: 0.7500\n",
      "Epoch 164/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4796 - accuracy: 0.7875 - val_loss: 0.5679 - val_accuracy: 0.7500\n",
      "Epoch 165/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4748 - accuracy: 0.8125 - val_loss: 0.5622 - val_accuracy: 0.7500\n",
      "Epoch 166/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4826 - accuracy: 0.8000 - val_loss: 0.5570 - val_accuracy: 0.7500\n",
      "Epoch 167/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4752 - accuracy: 0.7750 - val_loss: 0.5527 - val_accuracy: 0.7500\n",
      "Epoch 168/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4870 - accuracy: 0.8125 - val_loss: 0.5500 - val_accuracy: 0.7500\n",
      "Epoch 169/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4700 - accuracy: 0.8000 - val_loss: 0.5483 - val_accuracy: 0.7500\n",
      "Epoch 170/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4736 - accuracy: 0.7875 - val_loss: 0.5467 - val_accuracy: 0.7500\n",
      "Epoch 171/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4950 - accuracy: 0.8000 - val_loss: 0.5448 - val_accuracy: 0.7500\n",
      "Epoch 172/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4727 - accuracy: 0.7875 - val_loss: 0.5443 - val_accuracy: 0.7500\n",
      "Epoch 173/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4861 - accuracy: 0.7750 - val_loss: 0.5455 - val_accuracy: 0.7500\n",
      "Epoch 174/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4566 - accuracy: 0.8250 - val_loss: 0.5454 - val_accuracy: 0.7500\n",
      "Epoch 175/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4795 - accuracy: 0.8000 - val_loss: 0.5443 - val_accuracy: 0.7500\n",
      "Epoch 176/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4517 - accuracy: 0.8375 - val_loss: 0.5436 - val_accuracy: 0.7500\n",
      "Epoch 177/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4652 - accuracy: 0.8000 - val_loss: 0.5427 - val_accuracy: 0.7500\n",
      "Epoch 178/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4639 - accuracy: 0.8000 - val_loss: 0.5399 - val_accuracy: 0.7500\n",
      "Epoch 179/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4470 - accuracy: 0.8125 - val_loss: 0.5366 - val_accuracy: 0.7500\n",
      "Epoch 180/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4624 - accuracy: 0.7875 - val_loss: 0.5334 - val_accuracy: 0.7500\n",
      "Epoch 181/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4700 - accuracy: 0.8000 - val_loss: 0.5318 - val_accuracy: 0.7500\n",
      "Epoch 182/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4552 - accuracy: 0.8250 - val_loss: 0.5305 - val_accuracy: 0.7500\n",
      "Epoch 183/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4576 - accuracy: 0.7875 - val_loss: 0.5292 - val_accuracy: 0.7500\n",
      "Epoch 184/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4691 - accuracy: 0.8000 - val_loss: 0.5285 - val_accuracy: 0.7500\n",
      "Epoch 185/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4668 - accuracy: 0.7875 - val_loss: 0.5265 - val_accuracy: 0.7500\n",
      "Epoch 186/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4517 - accuracy: 0.8250 - val_loss: 0.5226 - val_accuracy: 0.7500\n",
      "Epoch 187/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4648 - accuracy: 0.7875 - val_loss: 0.5207 - val_accuracy: 0.7500\n",
      "Epoch 188/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4675 - accuracy: 0.8125 - val_loss: 0.5189 - val_accuracy: 0.7500\n",
      "Epoch 189/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4505 - accuracy: 0.7875 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
      "Epoch 190/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4709 - accuracy: 0.7875 - val_loss: 0.5148 - val_accuracy: 0.8000\n",
      "Epoch 191/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4668 - accuracy: 0.7750 - val_loss: 0.5140 - val_accuracy: 0.8000\n",
      "Epoch 192/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4399 - accuracy: 0.8250 - val_loss: 0.5121 - val_accuracy: 0.8000\n",
      "Epoch 193/200\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4427 - accuracy: 0.8125 - val_loss: 0.5117 - val_accuracy: 0.8000\n",
      "Epoch 194/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4394 - accuracy: 0.8125 - val_loss: 0.5115 - val_accuracy: 0.8000\n",
      "Epoch 195/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4791 - accuracy: 0.8250 - val_loss: 0.5099 - val_accuracy: 0.8000\n",
      "Epoch 196/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4506 - accuracy: 0.8000 - val_loss: 0.5091 - val_accuracy: 0.8000\n",
      "Epoch 197/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4543 - accuracy: 0.8000 - val_loss: 0.5082 - val_accuracy: 0.8000\n",
      "Epoch 198/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4457 - accuracy: 0.8125 - val_loss: 0.5067 - val_accuracy: 0.8000\n",
      "Epoch 199/200\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4483 - accuracy: 0.7875 - val_loss: 0.5050 - val_accuracy: 0.8000\n",
      "Epoch 200/200\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4582 - accuracy: 0.8250 - val_loss: 0.5034 - val_accuracy: 0.8000\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "history2 = model.fit(X,y,epochs=200,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f891cb0310>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history1.history['val_accuracy'],color='black')\n",
    "plt.plot(history2.history['val_accuracy'],color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
